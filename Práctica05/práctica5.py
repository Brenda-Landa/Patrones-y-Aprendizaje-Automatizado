# -*- coding: utf-8 -*-
"""Práctica5

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11LY3guAtuTtpgdIOQG9fuyPHBMlWYUQ1
"""

import numpy as np

help(np.random.rayleigh)

# Generar una muestra aleatoria de 10, 000 puntos de la distribuci ́on de Rayleigh utilizando scale = 7.53
# Obtén 160 puntos del histograma de tu muestra
scale = 7.53
N = 10000
nbins = 160

rayleigh_data = np.random.rayleigh(scale=scale, size=N)

rayleigh_data

# Función de densidad de Rayleigh
x = np.linspace(0, max(rayleigh_data), 100)
pdf = (x /scale **2) * np.exp(-x**2 / (2 * scale**2))

# Puntos para entrenamiento
hist, bin_edges = np.histogram(rayleigh_data, bins=nbins, density=True)

import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression,Ridge, Lasso
from sklearn.preprocessing import PolynomialFeatures
from sklearn.model_selection import train_test_split
y = hist


# Dividir los datos en conjuntos de entrenamiento y prueba
xtrain, xtest, ytrain, ytest = train_test_split(bin_edges[:-1].reshape(-1, 1), y, test_size=0.2, random_state=0)



# Inicializar el modelo de regresión lineal y ajustarlo
regressor = LinearRegression()
regressor.fit(xtrain, ytrain)

# Predecir usando el conjunto de prueba
pred_test = regressor.predict(xtest)
pred_train = regressor.predict(xtrain)

# Visualizar los resultados
plt.scatter(xtrain, ytrain, color='orange')
plt.plot(xtrain, pred_train, color='red')
plt.title('Modelo de Regresión (Conjunto de Entrenamiento)')
plt.xlabel('X')
plt.ylabel('y')
plt.show()

degree = 5 # 2,30  # Grado del polinomio
poly_features = PolynomialFeatures(degree=degree, include_bias=False)
X_poly_train = poly_features.fit_transform(xtrain)
X_poly_test = poly_features.transform(xtest)
lin_reg = LinearRegression()
lin_reg.fit(X_poly_train, ytrain)


#predicciones
y_pred_test = lin_reg.predict(X_poly_test)
y_pred_train = lin_reg.predict(X_poly_train)


X_new=np.linspace(0, 35, 100).reshape(100, 1)
X_new_poly = poly_features.transform(X_new)
y_new = lin_reg.predict(X_new_poly)

plt.figure(figsize=(10, 6))
plt.subplot(1, 2, 1)
plt.scatter(xtrain, ytrain, label='Datos de entrenamiento')
plt.plot(X_new, y_new, 'r-', linewidth=2, label='Regresión polinomial')
plt.xlabel('X')
plt.ylabel('y')
plt.title('Training: Regresión polinomial')
plt.legend()
plt.grid(True)


# Gráfica de prueba
plt.subplot(1, 2, 2)
plt.scatter(xtest, ytest, label='Datos de prueba')
plt.plot(X_new, y_new, 'r-', linewidth=2, label='Regresión polinomial')
plt.xlabel('X')
plt.ylabel('y')
plt.title('Test: Regresión polinomial')
plt.legend()
plt.grid(True)


plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression,Ridge, Lasso
from sklearn.preprocessing import PolynomialFeatures
from sklearn.model_selection import train_test_split
y = hist


# Dividir los datos en conjuntos de entrenamiento y prueba
xtrain, xtest, ytrain, ytest = train_test_split(bin_edges[:-1].reshape(-1, 1), y, test_size=0.2, random_state=0)



# Inicializar el modelo de regresión lineal y ajustarlo
regressor = LinearRegression()
regressor.fit(xtrain, ytrain)

# Predecir usando el conjunto de prueba
pred_test = regressor.predict(xtest)
pred_train = regressor.predict(xtrain)

# Visualizar los resultados
plt.scatter(xtrain, ytrain, color='orange')
plt.plot(xtrain, pred_train, color='red')
plt.title('Modelo de Regresión (Conjunto de Entrenamiento)')
plt.xlabel('X')
plt.ylabel('y')
plt.show()

degree = 5 # 2,30  # Grado del polinomio
poly_features = PolynomialFeatures(degree=degree, include_bias=False)
X_poly_train = poly_features.fit_transform(xtrain)
X_poly_test = poly_features.transform(xtest)
lin_reg = LinearRegression()
lin_reg.fit(X_poly_train, ytrain)


#predicciones
y_pred_test = lin_reg.predict(X_poly_test)
y_pred_train = lin_reg.predict(X_poly_train)


X_new=np.linspace(0, 35, 100).reshape(100, 1)
X_new_poly = poly_features.transform(X_new)
y_new = lin_reg.predict(X_new_poly)

plt.figure(figsize=(10, 6))
plt.subplot(1, 2, 1)
plt.scatter(xtrain, ytrain, label='Datos de entrenamiento')
plt.plot(X_new, y_new, 'r-', linewidth=2, label='Regresión polinomial')
plt.xlabel('X')
plt.ylabel('y')
plt.title('Training: Regresión polinomial')
plt.legend()
plt.grid(True)


# Gráfica de prueba
plt.subplot(1, 2, 2)
plt.scatter(xtest, ytest, label='Datos de prueba')
plt.plot(X_new, y_new, 'r-', linewidth=2, label='Regresión polinomial')
plt.xlabel('X')
plt.ylabel('y')
plt.title('Test: Regresión polinomial')
plt.legend()
plt.grid(True)


plt.tight_layout()
plt.show()

from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.model_selection import train_test_split
import pandas as pd


# Dividir los datos en conjunto de entrenamiento y prueba
xtrain, xtest, ytrain, ytest = train_test_split(bin_edges[:-1].reshape(-1, 1), y, test_size=0.2, random_state=0)

results = []

for degree in degrees_poly:
    poly_features = PolynomialFeatures(degree=degree, include_bias=False)
    X_poly_train = poly_features.fit_transform(xtrain)
    X_poly_test = poly_features.transform(xtest)
    model = LinearRegression()
    model.fit(X_poly_train, ytrain)

    # Predicciones en conjunto de entrenamiento y prueba
    y_train_pred = model.predict(X_poly_train)
    y_test_pred = model.predict(X_poly_test)

    # Calcular sesgo y varianza en conjunto de entrenamiento
    bias_train = np.mean((y_train_pred - ytrain) ** 2)
    variance_train = np.mean((np.mean(y_train_pred) - y_train_pred) ** 2)

    # Calcular métricas en conjunto de entrenamiento
    mae_train = mean_absolute_error(ytrain, y_train_pred)
    mse_train = mean_squared_error(ytrain, y_train_pred)
    r2_train = r2_score(ytrain, y_train_pred)

    # Calcular métricas en conjunto de prueba
    mae_test = mean_absolute_error(ytest, y_test_pred)
    mse_test = mean_squared_error(ytest, y_test_pred)
    r2_test = r2_score(ytest, y_test_pred)

    results.append({
        'Grado del polinomio': degree,
        'Sesgo (Train)': bias_train,
        'Varianza (Train)': variance_train,
        'MAE (Train)': mae_train,
        'MSE (Train)': mse_train,
        'R^2 (Train)': r2_train,
        'MAE (Test)': mae_test,
        'MSE (Test)': mse_test,
        'R^2 (Test)': r2_test
    })

results_df = pd.DataFrame(results)
print(results_df)